// Copyright 1998-2019 Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	SubsurfaceBurleyNormalized.usf: Screenspace Burley subsurface scattering implementation.
=============================================================================*/

#include "Common.ush"
#include "Random.ush"
#include "PostProcessCommon.ush"
#include "DeferredShadingCommon.ush"
#include "SubsurfaceProfileCommon.ush"
#include "BurleyNormalizedSSSCommon.ush"

#include "ScreenPass.ush"

// x:Radius*DistanceToProjectionWindow/KernelSize*0.5, y:DistanceToProjectionWindow, zw: unused
float4 SubsurfaceParams;

Texture2D SubsurfaceInput0_Texture;
Texture2D SubsurfaceInput1_Texture;

SamplerState SubsurfaceSampler0;
SamplerState SubsurfaceSampler1;

#if SUPPORTS_INDEPENDENT_SAMPLERS
	#define SharedSubsurfaceSampler0 SubsurfaceSampler0
	#define SharedSubsurfaceSampler1 SubsurfaceSampler0
#else
	#define SharedSubsurfaceSampler0 SubsurfaceSampler0
	#define SharedSubsurfaceSampler1 SubsurfaceSampler1
#endif

SCREEN_PASS_TEXTURE_VIEWPORT(SubsurfaceInput0)
SCREEN_PASS_TEXTURE_VIEWPORT(SubsurfaceInput1)

#define SUBSURFACE_PASS_ONE 0
#define SUBSURFACE_PASS_TWO 1

#define SUBSURFACE_DIRECTION_HORIZONTAL SUBSURFACE_PASS_ONE
#define SUBSURFACE_DIRECTION_VERTICAL SUBSURFACE_PASS_TWO

// Controls the quality (number of samples) of the blur kernel.
#define SUBSURFACE_QUALITY_LOW 0
#define SUBSURFACE_QUALITY_MEDIUM 1
#define SUBSURFACE_QUALITY_HIGH 2

// Full resolution recombine.
#define SUBSURFACE_RECOMBINE_MODE_FULLRES 0

// Half resolution recombine.
#define SUBSURFACE_RECOMBINE_MODE_HALFRES 1

// Just reconstruct the lighting (needed for scalability).
#define SUBSURFACE_RECOMBINE_MODE_NO_SCATTERING 2

// Controls the quality of lighting reconstruction.
#define SUBSURFACE_RECOMBINE_QUALITY_LOW 0
#define SUBSURFACE_RECOMBINE_QUALITY_HIGH 1

#ifndef SUBSURFACE_RECOMBINE_QUALITY
	#define SUBSURFACE_RECOMBINE_QUALITY SUBSURFACE_RECOMBINE_QUALITY_LOW
#endif

#if SUBSURFACE_RECOMBINE_QUALITY == SUBSURFACE_RECOMBINE_QUALITY_HALFRES
	#define SUBSURFACE_HALFRES 1
#endif

//=============================================================================
// Setup for "Burley"
//=============================================================================

#define BURLEY_NUM_SAMPLES	64
#define BURLEY_INV_NUM_SAMPLES (1.0f/BURLEY_NUM_SAMPLES)

struct FBurleyParameter
{
	float4 SurfaceAlbedo;
	float4 DiffuseMeanFreePath;
	float  WorldScale;
};

//volume albedo and mean free path length
float4 GetSubsurfaceProfileSurfaceAlbedo(FGBufferData GBufferData)
{
	// 0..255, which SubSurface profile to pick
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(GBufferData);
	//SSSS_KERNEL0_OFFSET
	return ActualSSProfilesTexture.Load(int3(SSS__SURFACEALBEDO_OFFSET, SubsurfaceProfileInt, 0));
}

float4 GetSubsurfaceProfileDiffuseMeanFreePath(FGBufferData GBufferData)
{
	// 0..255, which SubSurface profile to pick
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(GBufferData);
	//SSSS_KERNEL0_OFFSET
	return ActualSSProfilesTexture.Load(int3(SSS__DMFP_OFFSET, SubsurfaceProfileInt, 0));
}

float GetSubsurfaceProfileWorldScale(FGBufferData GBufferData)
{
	// 0..255, which SubSurface profile to pick
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(GBufferData);

	return ActualSSProfilesTexture.Load(int3(SSSS_SUBSURFACE_COLOR_OFFSET, SubsurfaceProfileInt,0)).a;
}

// fetch volume albedo and diffuse mean free path
// The diffuse mean free path is modulated by ScatterRadius and a custom term passed in
// which is the opacity texture.
FBurleyParameter GetBurleyParameters(FGBufferData GBuffer)
{
	FBurleyParameter BurleyParameter;

	BurleyParameter.SurfaceAlbedo = GetSubsurfaceProfileSurfaceAlbedo(GBuffer);
	float4 DiffuseMeanFreePath = GetSubsurfaceProfileDiffuseMeanFreePath(GBuffer);
	BurleyParameter.DiffuseMeanFreePath = DecodeDiffuseMeanFreePath(DiffuseMeanFreePath);
	float WorldScale = DecodeWorldScale(GetSubsurfaceProfileWorldScale(GBuffer))*BURLEY_CM_2_MM;
	BurleyParameter.WorldScale = WorldScale;
	BRANCH
	if (GBuffer.ShadingModelID == SHADINGMODELID_SUBSURFACE_PROFILE)
	{
		// scale with opacity stored in CustomData.a
		BurleyParameter.DiffuseMeanFreePath *= GBuffer.CustomData.a;
	}
	else if (GBuffer.ShadingModelID == SHADINGMODELID_EYE)
	{
		//eye 
	}
	return BurleyParameter;
}

float2 Generate2DRandomNumber(int3 Seed)
{
	return float2(Rand3DPCG16(Seed).xy) / 0x10000;
}

float GetCDF(float D, float X, float XI)
{
	return 1 - 0.25*exp(-X / D) - 0.75*exp(-X / (3 * D)) - XI;
}
float GetCDFDeriv1(float D, float X)
{
	return 0.25 / D * (exp(-X / D) + exp(-X / (3 * D)));
}

float GetCDFDeriv2(float D, float X)
{
	return exp(-X / D)*(-0.0833333*exp(2 * X / (3 * D)) - 0.25) / (D*D);
}

// Without clamp, the result will be zero which will lead to infinity for R/pdf. and Nan for the weighted sum.
// We need to clamp this to a very small pdf. this clamp is based on value below
#define CLAMP_PDF 0.00001

// Given D and a random number, use root finding method to calculate the radius
// in meters
float RadiusRootFinding(float D, float RandomNumber, float X0)
{
	// Make the distribution correct.
	// r=cdf^(-1)(p)     if p<1-CLAMP_PDF
	//  =cdf^(-1)(1-ClAMP_PDF) P>=1-CLAMP_PDF
	// RandomNumber = clamp(RandomNumber,0,1-CLAMP_PDF);
 
	const int NumOfIteration = 3;
	float Xn = X0;

	UNROLL
		for (int i = 0; i < NumOfIteration; ++i)
		{
			float Fx = GetCDF(D, Xn, RandomNumber);
			float DFx = GetCDFDeriv1(D, Xn);
			float DFxx = GetCDFDeriv2(D, Xn);
			Xn = Xn - 2 * Fx*DFx / (2 * DFx*DFx - Fx * DFxx);
		}
	return Xn;
}

//Brian's approximation.
float RadiusRootFindByApproximation(float D, float RandomNumber)
{
	return D * ((2 - 2.6)*RandomNumber - 2)*log(1-RandomNumber);
}

// get the probability to sample a disk.
float GetPdf(float Radius, float L, float S)
{
	//without clamp, the result will be zero which will lead to infinity for R/pdf. and Nan for the weighted sum.
	//we need to clamp this to a very small pdf.

	float Pdf = GetCDFDeriv1(L / S, Radius);
	return clamp(Pdf, CLAMP_PDF, 1);
}

struct FBurleySampleInfo
{
	float Radius;
	float Theta;
	float Pdf;
};

FBurleySampleInfo GenerateSampleInfo(float2 Rand0T1,float DiffuseMeanFreePathForSample, float SpectralForSample,uint SequenceId)
{
	FBurleySampleInfo BurleySampleInfo;

#define RADIUS_SAMPLE_PDF
#ifdef RADIUS_SAMPLE_UNIFORM_DISK

	float RadiusSampled = max(DiffuseMeanFreePathForSample * sqrtFast(Rand0T1.x), 0.0001f);//should not be zero
	float Pdf = 1 / (2 * PI);	// use actual pdf
	float Theta = Rand0T1.y * 2 * PI;
#elif defined(RADIUS_SAMPLE_PDF)

#define ROOT_APROXIMATE

#ifdef ROOT_FINDING
	float FoundRoot = RadiusRootFinding(DiffuseMeanFreePathForSample / SpectralForSample, Rand0T1.x, DiffuseMeanFreePathForSample);
#elif defined(ROOT_APROXIMATE)
	//Approximation
	float FoundRoot = RadiusRootFindByApproximation(DiffuseMeanFreePathForSample / SpectralForSample,Rand0T1.x);
#endif
	BurleySampleInfo.Radius = max(FoundRoot, 0.00001f);//in mm

#define SAMPLE_ANGLE_FIBONACCI	
#ifdef SAMPLE_ANGLE_RANDOM
	BurleySampleInfo.Theta = Rand0T1.y * 2 * PI;
#elif defined(SAMPLE_ANGLE_FIBONACCI)
	//Less variance
	BurleySampleInfo.Theta = (((SequenceId + 0.5 + Rand0T1.y))*(1 + sqrt(5))*0.5) * 2 * PI;//Fibonacci sequence for angle.
#endif
	BurleySampleInfo.Pdf = GetPdf(BurleySampleInfo.Radius, DiffuseMeanFreePathForSample, SpectralForSample); //
#endif

	return BurleySampleInfo;
}

//=============================================================================
// setup for "SeparableSSS.ush"
//=============================================================================

#if SUBSURFACE_QUALITY == SUBSURFACE_QUALITY_LOW
	#define	SSSS_N_KERNELWEIGHTCOUNT SSSS_KERNEL2_SIZE
	#define	SSSS_N_KERNELWEIGHTOFFSET SSSS_KERNEL2_OFFSET
#elif SUBSURFACE_QUALITY == SUBSURFACE_QUALITY_MEDIUM
	#define	SSSS_N_KERNELWEIGHTCOUNT SSSS_KERNEL1_SIZE
	#define	SSSS_N_KERNELWEIGHTOFFSET SSSS_KERNEL1_OFFSET
#else // SUBSURFACE_QUALITY == SUBSURFACE_QUALITY_HIGH
	#define	SSSS_N_KERNELWEIGHTCOUNT SSSS_KERNEL0_SIZE
	#define	SSSS_N_KERNELWEIGHTOFFSET SSSS_KERNEL0_OFFSET
#endif

// 0: faster
// 1: no color bleeding in z direction
#define SSSS_FOLLOW_SURFACE 1

float GetMaskFromDepthInAlpha(float Alpha)
{
	return Alpha > 0;
}

// can be optimized
float GetSubsurfaceStrength(float2 UV)
{
	FScreenSpaceData ScreenSpaceData = GetScreenSpaceData(UV);

	float Mask = UseSubsurfaceProfile(ScreenSpaceData.GBuffer.ShadingModelID) ? 1.0f : 0.0f;
	return Mask * ScreenSpaceData.GBuffer.CustomData.a;
}

// @return .rgb is the weight for color channel, .a is the sample location
float4 GetSubsurfaceProfileKernel(uint SampleIndex, uint SubsurfaceProfileInt)
{
	const float4 TableMax = float4(1, 1, 1, SUBSURFACE_KERNEL_SIZE);

	return ActualSSProfilesTexture.Load(int3(SampleIndex, SubsurfaceProfileInt, 0)) * TableMax;
}

float GetSubsurfaceProfileRadiusScale(FGBufferData GBufferData)
{
	// 0..255, which SubSurface profile to pick
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(GBufferData);

	return GetSubsurfaceProfileKernel(SSSS_N_KERNELWEIGHTOFFSET + SSSS_N_KERNELWEIGHTCOUNT - 1, SubsurfaceProfileInt).a;
}

float3 GetSubsurfaceProfileColor(FGBufferData GBufferData)
{
	// 0..255, which SubSurface profile to pick
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(GBufferData);

	return GetSubsurfaceProfileKernel(SSSS_SUBSURFACE_COLOR_OFFSET, SubsurfaceProfileInt).rgb;
}

uint GetSubsurfaceProfileId(float2 BufferUV)
{
	BufferUV = clamp(BufferUV, SubsurfaceInput0_UVViewportBilinearMin, SubsurfaceInput0_UVViewportBilinearMax);

	FGBufferData LocalGBufferData = GetGBufferData(BufferUV);
	return ExtractSubsurfaceProfileInt(LocalGBufferData);
}

float3 GetSubsurfaceProfileBoundaryColorBleed(FGBufferData GBufferData)
{
	// 0..255, which SubSurface profile to pick
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(GBufferData);

	return GetSubsurfaceProfileKernel(SSSS_BOUNDARY_COLOR_BLEED_OFFSET, SubsurfaceProfileInt).rgb;
}

float4 GetSceneColor(float2 BufferUV)
{
	BufferUV = clamp(BufferUV, SubsurfaceInput0_UVViewportBilinearMin, SubsurfaceInput0_UVViewportBilinearMax);

	return Texture2DSampleLevel(SubsurfaceInput0_Texture, SharedSubsurfaceSampler0, BufferUV, 0);
}

// from https://github.com/iryoku/separable-sss/tree/master/Demo
// Jorge Jimenez http://www.iryoku.com/
// http://www.iryoku.com/translucency/downloads/Real-Time-Realistic-Skin-Translucency.pdf
#include "SeparableSSS.ush"

//=============================================================================

bool InUnitBox(float2 UV)
{
	return UV.x >= 0 && UV.y >= 0 && UV.y < 1 && UV.y < 1;
}

// @return 0=don't blend in, 1:fully blend in
float ComputeFullResLerp(FScreenSpaceData ScreenSpaceData, float2 UVSceneColor, float2 FullResInputSizeInverse)
{
	float SSSScaleX = SubsurfaceParams.x;

	float scale = SSSScaleX / CalcSceneDepth(UVSceneColor);

	float HorizontalScaler = SUBSURFACE_RADIUS_SCALE;

	// Calculate the final step to fetch the surrounding pixels:
	float finalStep = scale * HorizontalScaler;

	finalStep *= GetSubsurfaceProfileRadiusScale(ScreenSpaceData.GBuffer);

	float PixelSizeRadius = finalStep / (FullResInputSizeInverse.x * 0.5f);

	// tweaked for skin, a more flat kernel might need a smaller value, around 2 seems reasonable because we do half res
	const float PixelSize = 4.0f;

	float Ret = saturate(PixelSizeRadius - PixelSize);

	// opacity allows to scale the radius - at some point we should fade in the full resolution, we don't have a masking other than that.
	Ret *= saturate(ScreenSpaceData.GBuffer.CustomData.a * 10);

	// todo: Subsurface has some non scatter contribution - all that should come from the Full res
	return Ret;
}

struct SDiffuseAndSpecular
{
	float3 Diffuse;
	float3 Specular;
};

// can be moved/shared
half3 LookupSceneColor(float2 SceneUV, int2 PixelOffset)
{
#if ES2_PROFILE && COMPILER_GLSL_ES2
	// slower but always works
	// to prevent "error: Texture offset not supported on GLSL ES"
	return Texture2DSample(SubsurfaceInput0_Texture, SharedSubsurfaceSampler0, SceneUV + PixelOffset * SubsurfaceInput0_ExtentInverse).rgb;
#else
	// faster
	return SubsurfaceInput0_Texture.SampleLevel(SharedSubsurfaceSampler0, SceneUV, 0, PixelOffset).rgb;
#endif
}
 
// @param UVSceneColor for the full res rendertarget (BufferSize) e.g. SceneColor or GBuffers
// @param ReconstructMethod 0/1/2/3 (should be a literal constant to allow compiler optimizations)
SDiffuseAndSpecular ReconstructLighting(float2 UVSceneColor, uint ReconstructMethod)
{
	SDiffuseAndSpecular Ret;

	// If SUBSURFACE_CHANNEL_MODE is 0, checkerboard is forced on
#if SUBSURFACE_PROFILE_CHECKERBOARD || SUBSURFACE_CHANNEL_MODE == 0
	{
	  bool bChecker = CheckerFromSceneColorUV(UVSceneColor);

	  // todo: We could alternate the diagonal with TemporalAA or even only only 1 sample for low spec or 4 for high spec

	  float3 Quant0 = SubsurfaceInput0_Texture.SampleLevel(SharedSubsurfaceSampler0, UVSceneColor, 0).rgb;

	  // todo: expose as scalability setting (can be evaluate best without TemporalAA)
	  // 0:fast but pattern can appear, 1:better, 2: even better, 3: best but expensive
	  float3 Quant1;

	  if(ReconstructMethod == 0)
	  {
		  // cheap, crappy
		  Quant1 = LookupSceneColor(UVSceneColor, int2(1, 0));
	  }
	  else if(ReconstructMethod == 1)
	  {
		  // acceptable but not perfect
		  Quant1 = 0.5f * (
			  LookupSceneColor(UVSceneColor, int2( 1, 0)) +
			  LookupSceneColor(UVSceneColor, int2(-1, 0)));
	  }
	  else if(ReconstructMethod == 2)
	  {
		  // almost same as 1?
		  Quant1 = 0.25f * (
			  LookupSceneColor(UVSceneColor, int2( 1,  0)) +
			  LookupSceneColor(UVSceneColor, int2( 0,  1)) +
			  LookupSceneColor(UVSceneColor, int2(-1,  0)) +
			  LookupSceneColor(UVSceneColor, int2( 0, -1)));
	  }
	  else if(ReconstructMethod == 3)
	  {
		  // very good 
		  float3 A = LookupSceneColor(UVSceneColor, int2( 1,  0));
		  float3 B = LookupSceneColor(UVSceneColor, int2(-1,  0));
		  float3 C = LookupSceneColor(UVSceneColor, int2( 0,  1));
		  float3 D = LookupSceneColor(UVSceneColor, int2( 0, -1));

		  // Luminance could be green channel only
		  float a = Luminance(A);
		  float b = Luminance(B);
		  float c = Luminance(C);
		  float d = Luminance(D);

		  float ab = abs(a - b);
		  float cd = abs(c - d);

		  // take the average in the direction that avoids dither pattern
		  Quant1 = 0.5f * lerp(A + B, C + D, ab > cd);
	  }

	  Ret.Diffuse = lerp(Quant1, Quant0, bChecker);
	  Ret.Specular = lerp(Quant0, Quant1, bChecker);
	}
#else // SUBSURFACE_PROFILE_CHECKERBOARD
	{
	  // If we're not doing checkerboard encoding, we just need to read a single pixel and decode (combined diffuse/spec in RGB)
	  float4 CenterSample = SubsurfaceInput0_Texture.SampleLevel(SharedSubsurfaceSampler0, UVSceneColor, 0);
	  float3 CombinedColor = CenterSample.rgb;
	  float DiffuseLuminance = CenterSample.a * View.PreExposure;
  
	  float CombinedLuminance = Luminance(CombinedColor);
	  float DiffuseFactor = saturate(DiffuseLuminance / CombinedLuminance);
	  float SpecularFactor = 1.0f - DiffuseFactor;
  
	  Ret.Diffuse = CombinedColor * DiffuseFactor;
	  Ret.Specular = CombinedColor * SpecularFactor;
	}
#endif // !SUBSURFACE_PROFILE_CHECKERBOARD

	return Ret;
}

// @param UVSceneColor for the full res rendertarget (BufferSize) e.g. SceneColor or GBuffers
// @return .RGB Color that should be scattared, .A:1 for subsurface scattering material, 0 for not
float4 SetupSubsurfaceForOnePixel(float2 UVSceneColor)
{
	float4 Ret = 0;

	FScreenSpaceData ScreenSpaceData = GetScreenSpaceData(UVSceneColor);

	BRANCH if (UseSubsurfaceProfile(ScreenSpaceData.GBuffer.ShadingModelID))
	{
		// '1' is lower quality but that is acceptable here
		SDiffuseAndSpecular DiffuseAndSpecular = ReconstructLighting(UVSceneColor, 1);

		Ret.rgb = DiffuseAndSpecular.Diffuse;

		// it's a valid sample
		Ret.a = 1;
	}

	return Ret;
}

void SetupPS(in noperspective float4 UVAndScreenPos : TEXCOORD0, out float4 OutColor : SV_Target0)
{
	float2 BufferUV = UVAndScreenPos.xy;

#if SUBSURFACE_HALF_RES
	// order aligned with Gather() hardware implementation
	// RGB: color*A, A:weight 0 if no subsurface scattering

	float4 A = SetupSubsurfaceForOnePixel(min(BufferUV + float2(-0.5,  0.5f) * SubsurfaceInput0_ExtentInverse, SubsurfaceInput0_UVViewportBilinearMax));
	float4 B = SetupSubsurfaceForOnePixel(min(BufferUV + float2( 0.5,  0.5f) * SubsurfaceInput0_ExtentInverse, SubsurfaceInput0_UVViewportBilinearMax));
	float4 C = SetupSubsurfaceForOnePixel(min(BufferUV + float2( 0.5, -0.5f) * SubsurfaceInput0_ExtentInverse, SubsurfaceInput0_UVViewportBilinearMax));
	float4 D = SetupSubsurfaceForOnePixel(min(BufferUV + float2(-0.5, -0.5f) * SubsurfaceInput0_ExtentInverse, SubsurfaceInput0_UVViewportBilinearMax));

	float4 Sum = (A + B) + (C + D);

	float Div = 1.0f / max(Sum.a, 0.00001f);

	OutColor.rgb = Sum.rgb * Div;

	float4 FourDepth = GatherSceneDepth(BufferUV, SubsurfaceInput0_ExtentInverse);

	// average all valid depth values to a single one
	float SingleDepth = dot(FourDepth, float4(A.a, B.a, C.a, D.a)) * Div;

	OutColor.a = SingleDepth;
#else // SUBSURFACE_HALF_RES
	OutColor = SetupSubsurfaceForOnePixel(BufferUV);
	if(OutColor.a > 0)
	{
		OutColor.a = CalcSceneDepth(BufferUV);
	}
#endif // SUBSURFACE_HALF_RES
}

float RadiusRootFindingCM(float D, float RandomNumber, float X0)
{
	return RadiusRootFinding(D*0.01,RandomNumber,X0*0.01)*100.0f;
}

float GetPdfInCM(float Radius, float L, float S)
{
	return GetPdf(Radius *0.01f, L*0.01f, S);
}

float4 BurleyNormalizedSS(float2 BufferUV)
{
	FScreenSpaceData ScreenSpaceData = GetScreenSpaceData(BufferUV);

#ifdef SUBSURFACE_SINGLE_PASS
	float DepthAtDiscCenter = CalcSceneDepth(BufferUV);
	uint ReconstructMethod = (SUBSURFACE_RECOMBINE_QUALITY == SUBSURFACE_RECOMBINE_QUALITY_HIGH) ? 3 : 1;
#else
	float DepthAtDiscCenter = Texture2DSample(SubsurfaceInput0_Texture, SubsurfaceSampler0, BufferUV).w;
#endif

	float4 OutColor = 0;
	BRANCH if (DepthAtDiscCenter <= 0)
	{
		return OutColor;
	}

	FBurleyParameter BurleyParameter = GetBurleyParameters(ScreenSpaceData.GBuffer);
	float DiffuseMeanFreePathForSampling = GetDiffuseMeanFreePathForSampling(BurleyParameter.DiffuseMeanFreePath);
	float A = GetComponentForScalingFactorEstimation(BurleyParameter.SurfaceAlbedo);
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(ScreenSpaceData.GBuffer);
	float3 BoundaryColorBleed = GetSubsurfaceProfileBoundaryColorBleed(ScreenSpaceData.GBuffer).xyz;

#define LIGHT_PERPENDICULAR_DIFFUSE_SURFACE

#ifdef LIGHT_PERPENDICULAR
	float S = GetPerpendicularScalingFactor(A);
	float3 S3D = GetPerpendicularScalingFactor3D(BurleyParameter.SurfaceAlbedo);
#elif defined(LIGHT_DIFFUSESURFACE)
	float S = GetDiffuseSurfaceScalingFactor(A);
	float3 S3D = GetDiffuseSurfaceScalingFactor3D(BurleyParameter.SurfaceAlbedo);
#elif defined(LIGHT_PERPENDICULAR_DIFFUSE_SURFACE)
	float S = GetSearchLightDiffuseScalingFactor(A);
	float3 S3D = GetSearchLightDiffuseScalingFactor(BurleyParameter.SurfaceAlbedo.rgb);
#endif

	int SeedStart = View.FrameNumber;
	float3 WeightingFactor = 0.0f;
	float4 RadianceAccumulated = float4(0.0f, 0.0f, 0.0f, 1.0f);
	float Mask = 1.0f;

	LOOP
		for (int i = 0; i < BURLEY_NUM_SAMPLES; ++i)
		{
			//step 1: sample generation
			//create an 2d disk sampling pattern (we can load from the disk as a texture or buffer).
			int3  Seed3D = int3(BufferUV*SubsurfaceInput0_Extent, SeedStart++);
			float2 Random0T1 = Generate2DRandomNumber(Seed3D);
			FBurleySampleInfo BurleySampleInfo = GenerateSampleInfo(Random0T1, DiffuseMeanFreePathForSampling, S, i);

			//step 2: get the light radiance and depth at the offset
			//and estimate the scale from the random disk sampling space to sceen space.
			float YScale = BURLEY_MM_2_CM / DepthAtDiscCenter; //from mm to cm, and from world to screen
			float XScale = YScale * SubsurfaceInput0_ExtentInverse.x*SubsurfaceInput0_Extent.y;

			//world unit to screen space unit, we use world scale to control
			//the scaling of the radius unit when mean free path is fixed.
			float2 UVOffset = float2(XScale, YScale)*BurleySampleInfo.Radius*BurleyParameter.WorldScale;
			UVOffset.x *= cos(BurleySampleInfo.Theta);
			UVOffset.y *= sin(BurleySampleInfo.Theta);

			//Sampling
			{
				
				float2 SampledDiscUV = BufferUV + UVOffset;

#ifdef SUBSURFACE_SINGLE_PASS
				SDiffuseAndSpecular SampledDiffuseAndSpecular = ReconstructLighting(SampledDiscUV, ReconstructMethod);
				float4 SampledRadianceAndDepth = float4(SampledDiffuseAndSpecular.Diffuse, CalcSceneDepth(SampledDiscUV));
#else
				float4 SampledRadianceAndDepth = Texture2DSample(SubsurfaceInput0_Texture, SubsurfaceSampler0, SampledDiscUV);
#endif
				//Determine the tint color, if the sampling pixel is not subsurface, we use tint color
				//to mask out the sampling.
				uint LocalProfileInt = GetSubsurfaceProfileId(SampledDiscUV);
				float3 TintColor = (LocalProfileInt == SubsurfaceProfileInt) ? 1.0f : BoundaryColorBleed;
				Mask = UseSubsurfaceProfile(GetScreenSpaceData(SampledDiscUV).GBuffer.ShadingModelID)? 1 : 0;

				//step 3: create the bilateral filtering weighted Distance between entry and exit.
#define USE_BILATERAL_FILTERING

#ifdef USE_BILATERAL_FILTERING
				// 10.0/depth is the depth in world unit (cm)
				float DeltaDepth = min(abs(10.0f / SampledRadianceAndDepth.w - 10.0f / DepthAtDiscCenter), 60000)*BURLEY_CM_2_MM;//in mm
				float RadiusSampled = sqrt(BurleySampleInfo.Radius * BurleySampleInfo.Radius + DeltaDepth * DeltaDepth); //mm.
//#define RESAMPLE_PDF
#ifdef RESAMPLE_PDF
				BurleySampleInfo.Pdf = GetPdf(RadiusSampled, DiffuseMeanFreePathForSample, S);
#endif
#else
				float RadiusSampled = BurleySampleInfo.Radius;
#endif				

				//step 4: accumulate radiance from the diffusion profile rR(r)
				//make sure the DiffuseMeanFreePath is not zero and in m.
				float3 DiffusionProfile = GetDiffuseReflectProfileWithDiffuseMeanFreePath(BurleyParameter.SurfaceAlbedo, BurleyParameter.DiffuseMeanFreePath, S3D, RadiusSampled);
				RadianceAccumulated.xyz += (DiffusionProfile / BurleySampleInfo.Pdf) * (SampledRadianceAndDepth.xyz*TintColor*Mask);

#ifdef USE_BILATERAL_FILTERING
				WeightingFactor += (DiffusionProfile / BurleySampleInfo.Pdf) * Mask;
#endif
			}

		}

	//0.99995f is a compensitation to make it energe conservation.
	const float EnergyNormalization = 1.0f / 0.99995f;

#if defined(RADIUS_SAMPLE_UNIFORM_DISK)
	RadianceAccumulated.xyz *= (InvSampleCount*0.5 * 2 * PI);
#elif !defined(USE_BILATERAL_FILTERING)
	RadianceAccumulated.xyz *= (BURLEY_INV_NUM_SAMPLES*0.5 * 2 * PI) * EnergyNormalization;
#else
	//The added epsilon is used to avoid divid by zero.
	RadianceAccumulated.xyz *= 1.0f / (WeightingFactor + 0.000001f)*EnergyNormalization;
#endif

	OutColor.xyz = RadianceAccumulated.xyz;
	OutColor.w = 1.0f;// 1.0f;
	return OutColor;
}

// input0 is created by the SetupPS shader
void MainPS(noperspective float4 UVAndScreenPos : TEXCOORD0, out float4 OutColor : SV_Target0)
{
	
	float2 BufferUV = UVAndScreenPos.xy;

	//determine if we will use burley
	FScreenSpaceData ScreenSpaceData = GetScreenSpaceData(BufferUV);
	uint SubsurfaceProfileInt = ExtractSubsurfaceProfileInt(ScreenSpaceData.GBuffer);
	bool bUseBurley = GetSubsurfaceProfileUseBurley(SubsurfaceProfileInt);

	
#if SUBSURFACE_PASS == 0 || SUBSURFACE_PASS == SUBSURFACE_PASS_ONE

	BRANCH
	if (bUseBurley)
	{	//needs to perform burley normalized subsurface scattering
		OutColor = BurleyNormalizedSS(BufferUV);
		return;
	}

	// horizontal
	float2 ViewportDirectionUV = float2(1, 0) * SUBSURFACE_RADIUS_SCALE;
#else

	BRANCH
	if (bUseBurley)
	{
		//direct sample the color

		OutColor = Texture2DSample(SubsurfaceInput0_Texture, SubsurfaceSampler0, BufferUV);
		return;
	}
	// vertical
	float2 ViewportDirectionUV = float2(0, 1) * SUBSURFACE_RADIUS_SCALE * (SubsurfaceInput0_Extent.x * SubsurfaceInput0_ExtentInverse.y);
#endif

	ViewportDirectionUV *= (SubsurfaceInput0_ViewportSize.x * SubsurfaceInput0_ExtentInverse.x);

	OutColor = SSSSBlurPS(BufferUV, ViewportDirectionUV, false);

#if SUBSURFACE_PASS == SUBSURFACE_DIRECTION_VERTICAL || SUBSURFACE_PASS == SUBSURFACE_PASS_TWO
	// second pass prepares the setup from the recombine pass which doesn't need depth but wants to reconstruct the color
	OutColor.a = GetMaskFromDepthInAlpha(OutColor.a);
#endif
}

// Recombines the half res Subsurface filtered lighting contribution (upsampled and renormalized with the alpha)
// with the SceneColor.
void SubsurfaceRecombinePS(noperspective float4 UVAndScreenPos : TEXCOORD0, float4 SvPosition : SV_POSITION, out float4 OutColor : SV_Target0)
{

	float2 BufferUV = UVAndScreenPos.xy;

	FScreenSpaceData ScreenSpaceData = GetScreenSpaceData(BufferUV);
	
	if (!UseSubsurfaceProfile(ScreenSpaceData.GBuffer.ShadingModelID))
	{
		OutColor = Texture2DSample(SubsurfaceInput0_Texture, SharedSubsurfaceSampler0, BufferUV);
		return;
	}

	float3 SSSColor = float3(0, 0, 0);
	float LerpFactor = 1;

#if SUBSURFACE_RECOMBINE_MODE != SUBSURFACE_RECOMBINE_MODE_NO_SCATTERING
#if SUBSURFACE_HALF_RES
	// fade out subsurface scattering if radius is too small to be more crips (not blend with half resolution)
	// minor quality improvement (faces are more detailed in distance)
	LerpFactor = ComputeFullResLerp(ScreenSpaceData, BufferUV, SubsurfaceInput1_ExtentInverse);
#endif // SUBSURFACE_HALF_RES

	{
		float4 SSSColorWithAlpha = Texture2DSample(SubsurfaceInput1_Texture, SharedSubsurfaceSampler1, BufferUV);

		// renormalize to dilate RGB to fix half res upsampling artifacts
		SSSColor = SSSColorWithAlpha.rgb / max(SSSColorWithAlpha.a, 0.00001f);
	}
#else // SUBSURFACE_RECOMBINE_MODE == SUBSURFACE_RECOMBINE_MODE_NO_SCATTERING
	// Scalability requests no Scatter, but we still need to reconstruct a color
	LerpFactor = 0;
#endif // SUBSURFACE_RECOMBINE_MODE

	// we multiply the base color later in to get more crips human skin textures (scanned data always has Subsurface included)
	float3 StoredBaseColor = ScreenSpaceData.GBuffer.StoredBaseColor;
	float StoredSpecular = ScreenSpaceData.GBuffer.StoredSpecular;

	uint ReconstructMethod = (SUBSURFACE_RECOMBINE_QUALITY == SUBSURFACE_RECOMBINE_QUALITY_HIGH) ? 3 : 1;

	SDiffuseAndSpecular DiffuseAndSpecular = ReconstructLighting(BufferUV, ReconstructMethod);
	
	float3 ExtractedNonSubsurface = DiffuseAndSpecular.Specular;

	// asset specific color
	float3 SubsurfaceColor = GetSubsurfaceProfileColor(ScreenSpaceData.GBuffer);
	float3 FadedSubsurfaceColor = SubsurfaceColor * LerpFactor;

	//@TODO: clean up the separableSSS color
	// combine potentially half res with full res
	float3 SubsurfaceLighting =  lerp(DiffuseAndSpecular.Diffuse, SSSColor, FadedSubsurfaceColor);

	OutColor = float4(SubsurfaceLighting * StoredBaseColor + ExtractedNonSubsurface, 0); 
}

void SubsurfaceViewportCopyPS(noperspective float4 InUV : TEXCOORD0, out float4 OutColor : SV_Target0)
{
	OutColor = Texture2DSample(SubsurfaceInput0_Texture, SharedSubsurfaceSampler0, InUV.xy);
}

void SubsurfaceSinglePassPS(noperspective float4 InUV : TEXCOORD0, out float4 OutColor : SV_Target0)
{
	float2 BufferUV = InUV.xy;
	FScreenSpaceData ScreenSpaceData = GetScreenSpaceData(BufferUV);
	
	float DepthAtDiscCenter = CalcSceneDepth(BufferUV);
	
	bool bCopyScene = DepthAtDiscCenter <= 0 || (!UseSubsurfaceProfile(ScreenSpaceData.GBuffer.ShadingModelID));
#if SUBSURFACE_RECOMBINE_MODE == SUBSURFACE_RECOMBINE_MODE_NO_SCATTERING
	bCopyScene = true;
#endif

	//Setup data we are going to use.
	uint ReconstructMethod = (SUBSURFACE_RECOMBINE_QUALITY == SUBSURFACE_RECOMBINE_QUALITY_HIGH) ? 3 : 1;
	SDiffuseAndSpecular DiffuseAndSpecular = ReconstructLighting(BufferUV, ReconstructMethod);
	float4 StoredSceneColor = float4(DiffuseAndSpecular.Diffuse * ScreenSpaceData.GBuffer.StoredBaseColor + DiffuseAndSpecular.Specular,0);
	float LerpFactor = 1.0f;
	float4 MeanRadiance = float4(0.0f, 0.0f, 0.0f, 1.0f);

	BRANCH
		if (bCopyScene) {
			OutColor = StoredSceneColor;
			return;
		}

#if SUBSURFACE_RECOMBINE_MODE != SUBSURFACE_RECOMBINE_MODE_NO_SCATTERING
	MeanRadiance = BurleyNormalizedSS(BufferUV);

	//---------------------------------------------------------------------------
	// use the same logic as combine
	float3 SSSColor = MeanRadiance.rgb / max(MeanRadiance.a, 0.00001f);
	
	float3 SubsurfaceColor = GetSubsurfaceProfileColor(ScreenSpaceData.GBuffer);
	float3 FadedSubsurfaceColor = SubsurfaceColor * LerpFactor;
	//recombine with the normal and surface texture color
	float3 SubsurfaceLighting = lerp(DiffuseAndSpecular.Diffuse, SSSColor, FadedSubsurfaceColor);
	float3 ExtractedNonSubsurface = DiffuseAndSpecular.Specular;
	float3 StoredBaseColor = ScreenSpaceData.GBuffer.StoredBaseColor;

	OutColor = float4(SubsurfaceLighting * StoredBaseColor + ExtractedNonSubsurface,0);
#endif
}